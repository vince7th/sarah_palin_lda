{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/osboxes/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Import libraries\n",
    "\n",
    "import re\n",
    "# from stop_words import get_stop_words\n",
    "from nltk.corpus import stopwords\n",
    "# en_stop = get_stop_words('en') # avec package stop-words\n",
    "en_stop = set(stopwords.words('english'))\n",
    "\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "import csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Import and construct data\n",
    "fhand = open('sarah_palin/palindata.csv')\n",
    "email_number = []\n",
    "email_pure = []\n",
    "for line in fhand:\n",
    "    line = line.strip()\n",
    "    key_value  = line.split(',')\n",
    "    email_number.append(key_value)\n",
    "    email_pure.append(key_value[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Processing des mails : série d'expressions régulières pour cleaner les emails\n",
    "#    ainsi que pour réunir certaines chaînes de caractères sous une seule chaîne\n",
    "#    comme dollar, dollars, $, deviennent 'dollarmoneyprocess'. Voici les cleanings effectués :\n",
    "#\n",
    "#    remove web address\n",
    "#    remove emails address\n",
    "#    remove digits\n",
    "#    remove punctuation ():-_\n",
    "#    convert $ into dollars\n",
    "#    remove 2 length words and less \n",
    "#    remove stop words\n",
    "email_process_list = []\n",
    "for number,email in email_number:\n",
    "    email_process=[word for word in email.split() if word not in en_stop]\n",
    "    email_process=' '.join(email_process)\n",
    "    # email_process=re.sub(ur'(http:\\S+)', ' ' ,email_process)\n",
    "    email_process=re.sub(r'(http:\\S+)', ' ' ,email_process)\n",
    "    email_process=re.sub(r'(www\\.\\S+)', ' ' ,email_process)\n",
    "    email_process=re.sub(r'\\S+\\.com', ' ' ,email_process)\n",
    "    email_process=re.sub(r'\\S+@\\S+', ' ' ,email_process)\n",
    "    email_process=re.sub('\\d+', '', email_process)\n",
    "    email_process=re.sub(r'\\$','dollarmoneyprocess',email_process)\n",
    "    email_process=re.sub(r'[^\\w\\d\\s\\+]',' ',email_process)\n",
    "    email_process=re.sub(r'pm','timetableprocess',email_process)\n",
    "    email_process=re.sub(r'\\b\\w{1,2}\\b', ' ', email_process)\n",
    "    email_process=re.sub(r'\\S+_\\S*', '' ,email_process)\n",
    "    email_process=re.sub(r'_\\S*', '' ,email_process)\n",
    "    email_process=re.sub(r'\\s(dollars)\\s','dollarmoneyprocess',email_process)\n",
    "    email_process=re.sub(r'\\s(dollar)\\s','dollarmoneyprocess',email_process)\n",
    "    email_process=email_process.split()\n",
    "    email_process=set(email_process)\n",
    "    email_process_list.append((number,email_process))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.a) Fréquence des mots à travers la collection d'emails\n",
    "#      Les mots apparaissant dans trop de mails vont être supprimmés\n",
    "words_dico= {}\n",
    "for number,email in email_process_list:\n",
    "    for word in set(email):\n",
    "        if word not in words_dico:\n",
    "            words_dico[word]=1\n",
    "        else:\n",
    "            words_dico[word]=words_dico[word]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('pra', 9290), ('governor', 6519), ('state', 4770), ('mother', 4630), ('posted', 4594), ('pro', 4579), ('alaska', 4558), ('jones', 4547), ('searchable', 4508), ('analytics', 4508), ('publica', 4508), ('one', 4273), ('know', 3986), ('palin', 3683), ('message', 3472), ('address', 3214), ('mail', 3123), ('office', 2998), ('please', 2958), ('sent', 2949), ('thanks', 2900), ('time', 2866), ('web', 2749), ('anchorage', 2562), ('need', 2473), ('thank', 2461), ('gsp', 2456), ('from', 2395), ('new', 2391), ('today', 2360), ('juneau', 2229), ('sarah', 2179), ('device', 2088), ('cellular', 2062), ('director', 2042), ('blackberry', 2016), ('want', 1922), ('good', 1909), ('see', 1874), ('work', 1860), ('make', 1850), ('you', 1720), ('last', 1701), ('personal', 1686), ('email', 1647), ('call', 1633), ('first', 1620), ('people', 1556), ('year', 1538), ('well', 1519)]\n"
     ]
    }
   ],
   "source": [
    "# 3.b) On transforme le dictionnaire précédemment crée en liste afin de pouvoir le trier\n",
    "#      Affichage des 50 mots les plus fréquents\n",
    "words_freq = []\n",
    "for key, val in words_dico.items():\n",
    "    words_freq.append( (key, val) )\n",
    "words_freq.sort(key=lambda tup: tup[1] ,reverse=True)\n",
    "print (words_freq[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.a) Les mots apparaissant dans moins de 11 mails\n",
    "#    ainsi que les 30 mots les plus redondants parmi les emails\n",
    "#    sont enregistrés dans une liste words_to_delete\n",
    "words_to_delete1= [t[0] for t in words_freq if t[1] <11]\n",
    "words_to_delete2=[t[0] for t in words_freq[:30]]\n",
    "words_to_delete=words_to_delete1+words_to_delete2\n",
    "wtd =  {}\n",
    "for k in words_to_delete:\n",
    "    wtd[k]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 397 ms, sys: 22.9 ms, total: 420 ms\n",
      "Wall time: 447 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 4.b) On supprime les mots en question dans les emails\n",
    "#      itera est un compteur qui va nous servir plus tard\n",
    "#      ATTENTION : le temps de calcul est relativement long\n",
    "#      raison pour laquelle, on sauve la liste dans une copie à la fin\n",
    "email_process_list_new = []\n",
    "itera=0\n",
    "for number,email in email_process_list:\n",
    "    email_process=[word for word in email if word not in wtd.keys()]\n",
    "    email_process_list_new.append((itera,number,email_process))\n",
    "    itera=itera+1\n",
    "\n",
    "email_process_list_new2=email_process_list_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 422 ms, sys: 32.8 ms, total: 455 ms\n",
      "Wall time: 469 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 4.b) On supprime les mots en question dans les emails\n",
    "#      itera est un compteur qui va nous servir plus tard\n",
    "#      ATTENTION : le temps de calcul est relativement long\n",
    "#      raison pour laquelle, on sauve la liste dans une copie à la fin\n",
    "email_process_list_new = []\n",
    "itera=0\n",
    "for number,email in email_process_list:\n",
    "    email_process=[word for word in email if word not in wtd.keys()]\n",
    "    email_process_list_new.append((itera,number,email_process))\n",
    "    itera=itera+1\n",
    "\n",
    "email_process_list_new2=email_process_list_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.c) On supprime les emails contenant moins de 11 mots\n",
    "#      On crée une liste emailonly dans laquelle on ne stocke que les emails\n",
    "#      et rien d'autre\n",
    "for idx,email in enumerate(email_process_list_new2):\n",
    "    if len(email[2])<11:\n",
    "        del email_process_list_new2[idx]\n",
    "\n",
    "emailsonly=[x[2] for x in email_process_list_new2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Préparation avant lancement de la LDA, il nous faut créer deux objets gensim\n",
    "#    (*) un objet dictionary qui comprend tous les mots utilisés dans l'ensemble de la \n",
    "#    collection d'emails\n",
    "#    (*) un objet corpus (document term matrix) qui contient tous les emails mais sous\n",
    "#    la forme de vecteurs dont les éléments sont des 1s ou des 0s. 1 si le mot est\n",
    "#    présent dans le mail. 0 sinon.\n",
    "dictionary = corpora.Dictionary(emailsonly)\n",
    "corpus = [dictionary.doc2bow(text) for text in emailsonly]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Lancement de la LDA\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=30, id2word = dictionary, passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) On affche les topics (la distribution des 20 mots les plus fréquents qui définissent les topics)\n",
    "#    On peut également sauver les résultats du modèle et reload ces résultats avec les commandes\n",
    "#    save et load\n",
    "ldamodel.show_topics(num_topics=30, num_words=20, log=False, formatted=True)\n",
    "ldamodel.save('ldasaved')\n",
    "x=ldamodel.load('ldasaved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'psa todd governor - alaska children s trust film a 30 second psa todd encourage families listen talk play children. filmed (at syntax) between december 3-12 depending schedule. tell interested? sharon leighow deputy press secretary deputy communications director (907) 269-7450 anchorage (907) 465-4031 juneau (907) 240-7943 cell 1 pra_gsp01_0008001'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8) Distribution des topics d'un mail et son original\n",
    "x.show_topics(num_topics=30, num_words=20, log=False, formatted=True)\n",
    "x.get_document_topics(corpus[10], minimum_probability=None)\n",
    "email_process_list_new2[10]\n",
    "email_pure[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Sauvegarde de la distribution des mots par topic dans le fichier csv ldaoutput.csv\n",
    "topx=x.show_topics(num_topics=30, num_words=20, log=False, formatted=False)\n",
    "topic_word_distribution = []\n",
    "k=0\n",
    "for topic in topx:\n",
    "    for word in topic[1]:\n",
    "        topic_word_distribution.append((k,)+word)\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('C:\\Users\\Bar Yokhai\\Desktop\\python\\pythondir\\ldaoutput_best.csv', 'w') as output:\n",
    "    #writer = csv.writer(output, delimiter=';',lineterminator='\\n')\n",
    "    #for tweet in topic_word_distribution:\n",
    "        #writer.writerow([x.encode('utf-8') if isinstance(x, unicode) else x for x in tweet])   \n",
    "\n",
    "# 10) On sauve les mixtures de topics des emails dans ldaemailbest.csv\n",
    "topic_distribution_email=x.get_document_topics(corpus, minimum_probability=None)\n",
    "empty_tuple=[0] * 32\n",
    "list_email_topic_distribution=[empty_tuple[:] for _ in range(len(email_process_list_new2))]\n",
    "\n",
    "k=0\n",
    "for number,idx,email in email_process_list_new2:\n",
    "    #print (idx)\n",
    "    list_email_topic_distribution[k][0]=idx\n",
    "    list_email_topic_distribution[k][1]=len(email)\n",
    "    for topic in topic_distribution_email[k]:\n",
    "        list_email_topic_distribution[k][topic[0]+2]=topic[1]\n",
    "    k=k+1\n",
    "\n",
    "with open('ldaemailbest.csv', 'w') as output:\n",
    "    writer = csv.writer(output, delimiter=';',lineterminator='\\n')\n",
    "    for tweet in list_email_topic_distribution:\n",
    "        writer.writerow([x.encode('utf-8') if isinstance(x, unicode) else x for x in tweet])  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data bike sharing",
   "language": "python",
   "name": "data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
